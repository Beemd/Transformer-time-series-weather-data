{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "time_series_transformers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzP9p5MAVd8j"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAqFU8mBVufR"
      },
      "source": [
        "zip_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "    fname='jena_climate_2009_2016.csv.zip',\n",
        "    extract=True)\n",
        "csv_path, _ = os.path.splitext(zip_path)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT_p0eUaVyW2"
      },
      "source": [
        "#weather data collected after every 10 minutes. \n",
        "df = pd.read_csv(csv_path)\n",
        "#We want to predict the weather after every hour\n",
        "# slice [start:stop:step], starting from index 5 take every 6th record\n",
        "df = df[5::6]\n",
        "\n",
        "date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAnAKuxGaZ4m",
        "outputId": "a911165a-d0da-464e-a3e3-51222c29613e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#replacing erroneous values in the wind vecolity data, like -9999 with 0\n",
        "#min wind velocity\n",
        "wv = df['wv (m/s)']\n",
        "bad_wv = wv == -9999.0\n",
        "wv[bad_wv] = 0.0\n",
        "\n",
        "#max wind velocity\n",
        "max_wv = df['max. wv (m/s)']\n",
        "bad_max_wv = max_wv == -9999.0\n",
        "max_wv[bad_max_wv] = 0.0\n",
        "\n",
        "# The above inplace edits are reflected in the DataFrame\n",
        "df['wv (m/s)'].min()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeF8m7hdahRB"
      },
      "source": [
        "#convert wind direction and velocity columns to a wind vector for the model to interpret easily\n",
        "wv = df.pop('wv (m/s)')\n",
        "max_wv = df.pop('max. wv (m/s)')\n",
        "\n",
        "# Convert to radians\n",
        "wd_rad = df.pop('wd (deg)')*np.pi / 180\n",
        "\n",
        "# Calculate the wind x and y components\n",
        "df['Wx'] = wv*np.cos(wd_rad)\n",
        "df['Wy'] = wv*np.sin(wd_rad)\n",
        "\n",
        "# Calculate the max wind x and y components\n",
        "df['max Wx'] = max_wv*np.cos(wd_rad)\n",
        "df['max Wy'] = max_wv*np.sin(wd_rad)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvDKKsK-b_cd"
      },
      "source": [
        "#converting date-time into seconds\n",
        "timestamp_s = date_time.map(datetime.datetime.timestamp)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZFYAsTLcCOX"
      },
      "source": [
        "#converting the date-time in seconds into sinusoidal function using sine and cosine\n",
        "day = 24*60*60\n",
        "year = (365.2425)*day\n",
        "\n",
        "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
        "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
        "df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
        "df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJxRrDOWcIzU"
      },
      "source": [
        "#split data into training, validation and test (70%,20%,10%)\n",
        "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
        "\n",
        "n = len(df)\n",
        "train_df = df[0:int(n*0.7)]\n",
        "val_df = df[int(n*0.7):int(n*0.9)]\n",
        "test_df = df[int(n*0.9):]\n",
        "\n",
        "num_features = df.shape[1]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyQGnNGocKt-"
      },
      "source": [
        "#normalizing data by subtracting the mean and dividing by standard deviation.\n",
        "#mean and standard deviation are calculated using training data set only.\n",
        "train_mean = train_df.mean()\n",
        "train_std = train_df.std()\n",
        "\n",
        "train_df = (train_df - train_mean) / train_std\n",
        "val_df = (val_df - train_mean) / train_std\n",
        "test_df = (test_df - train_mean) / train_std"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFJe4y4GcPlw"
      },
      "source": [
        "class WindowGenerator():\n",
        "  def __init__(self, input_width, label_width, shift,\n",
        "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
        "               label_columns=None):\n",
        "    # Store the raw data.\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    # Work out the label column indices.\n",
        "    self.label_columns = label_columns\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "    # Work out the window parameters.\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])\n",
        "\n",
        "\n",
        "#separate windows for inputs and labels\n",
        "def split_window(self, features):\n",
        "  inputs = features[:, self.input_slice, :]\n",
        "  labels = features[:, self.labels_slice, :]\n",
        "  if self.label_columns is not None:\n",
        "    labels = tf.stack(\n",
        "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "        axis=-1)\n",
        "\n",
        "  # Slicing doesn't preserve static shape information, so set the shapes manually\n",
        "  inputs.set_shape([None, self.input_width, None])\n",
        "  labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "  return inputs, labels\n",
        "\n",
        "WindowGenerator.split_window = split_window\n",
        "\n",
        "\n",
        "#converting data into input_window and label_window pairs\n",
        "def make_dataset(self, data):\n",
        "  data = np.array(data, dtype=np.float32)\n",
        "  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "      data=data,\n",
        "      targets=None,\n",
        "      sequence_length=self.total_window_size,\n",
        "      sequence_stride=1,\n",
        "      shuffle=True,\n",
        "      batch_size=64,)\n",
        "\n",
        "  ds = ds.map(self.split_window)\n",
        "\n",
        "  return ds\n",
        "\n",
        "WindowGenerator.make_dataset = make_dataset\n",
        "\n",
        "\n",
        "@property\n",
        "def train(self):\n",
        "  return self.make_dataset(self.train_df)\n",
        "\n",
        "@property\n",
        "def val(self):\n",
        "  return self.make_dataset(self.val_df)\n",
        "\n",
        "@property\n",
        "def test(self):\n",
        "  return self.make_dataset(self.test_df)\n",
        "\n",
        "\n",
        "WindowGenerator.train = train\n",
        "WindowGenerator.val = val\n",
        "WindowGenerator.test = test\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37XlQOkAd3rF",
        "outputId": "53f32057-e643-408a-a442-9358278fa7dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#using WindowGenerator to define input and label windows\n",
        "#for temperature\n",
        "CONV_WIDTH = 24\n",
        "conv_window = WindowGenerator(\n",
        "    input_width=CONV_WIDTH,\n",
        "    label_width=1,\n",
        "    shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "conv_window"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Total window size: 25\n",
              "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
              "Label indices: [24]\n",
              "Label column name(s): ['T (degC)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtu4OuV5ZevR",
        "outputId": "42e40609-f538-445d-b513-b8f5a94fc377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "conv_window.train\n",
        "for example_inputs, example_labels in conv_window.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs shape (batch, time, features): (64, 24, 19)\n",
            "Labels shape (batch, time, features): (64, 1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDi5VVGVBraE"
      },
      "source": [
        "###Transformer Functions###"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA8k83K-_saA"
      },
      "source": [
        "###Positionsl Encoding\n",
        "\n",
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(100, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L4Z1elOLQm0"
      },
      "source": [
        "###Scaled Dot Product\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v):\n",
        "\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True) \n",
        "  \n",
        "  \n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  \n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  \n",
        "\n",
        "  return output, attention_weights\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2mb-aDIMrnr"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "  def split_heads(self, x, batch_size):\n",
        "\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, v, k, q):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v)\n",
        "    \n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  \n",
        "    output = self.dense(concat_attention)  \n",
        "        \n",
        "    return output, attention_weights"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a7_tXa7M792"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MXAOXEbM8fS"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, training):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    return out2"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhLmv18cNDxj"
      },
      "source": [
        "#Transformer encoding component\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, \n",
        "               maximum_position_encoding, rate):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                            self.d_model)    \n",
        "    \n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "  \n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    \n",
        "    # There are no embeddings - Just the input added to the positional encoding.\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training)\n",
        "    \n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR9s7ckINKjL"
      },
      "source": [
        "class Transformer(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers=4, d_model=24, num_heads=4, dff=16,  \n",
        "               pe_input=100, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, pe_input, rate)\n",
        "\n",
        "  def call(self, inp, training):\n",
        "\n",
        "    enc_output = self.encoder(inp, training)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    \n",
        "    return enc_output"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSx20qlt_8dO",
        "outputId": "60b3cf6f-3b47-451b-fa94-752e2a3b449d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "transformer_model = tf.keras.models.Sequential([\n",
        "    tf.keras.Input(shape=(24, 19)), \n",
        "    tf.keras.layers.Dense(24), \n",
        "    Transformer(),\n",
        "    tf.keras.layers.Dense(units=8),\n",
        "    #tf.keras.layers.\n",
        "    tf.keras.layers.GlobalMaxPooling1D(),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=1)  \n",
        "])\n",
        "\n",
        "\n",
        "MAX_EPOCHS = 20\n",
        "\n",
        "\n",
        "transformer_model.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "transformer_model.summary()\n",
        "\n",
        "history = transformer_model.fit(conv_window.train, epochs=MAX_EPOCHS,\n",
        "                      validation_data=conv_window.val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_107 (Dense)            (None, 24, 24)            480       \n",
            "_________________________________________________________________\n",
            "transformer_4 (Transformer)  (None, 24, 24)            13216     \n",
            "_________________________________________________________________\n",
            "dense_132 (Dense)            (None, 24, 8)             200       \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_4 (Glob (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_133 (Dense)            (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 13,905\n",
            "Trainable params: 13,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "767/767 [==============================] - 27s 35ms/step - loss: 0.1491 - mean_absolute_error: 0.2752 - val_loss: 0.2689 - val_mean_absolute_error: 0.4951\n",
            "Epoch 2/20\n",
            "767/767 [==============================] - 26s 33ms/step - loss: 0.0415 - mean_absolute_error: 0.1588 - val_loss: 0.1636 - val_mean_absolute_error: 0.3735\n",
            "Epoch 3/20\n",
            "767/767 [==============================] - 26s 34ms/step - loss: 0.0288 - mean_absolute_error: 0.1308 - val_loss: 0.0783 - val_mean_absolute_error: 0.2431\n",
            "Epoch 4/20\n",
            "122/767 [===>..........................] - ETA: 17s - loss: 0.0258 - mean_absolute_error: 0.1234"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_EpbOeqeJRX",
        "outputId": "88ad47f7-f493-417e-b2c2-d2fe241b2e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "val_performance['Transformer'] = transformer_model.evaluate(conv_window.train)\n",
        "performance['Transformer'] = transformer_model.evaluate(conv_window.val, verbose=0)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "767/767 [==============================] - 15s 19ms/step - loss: 0.0228 - mean_absolute_error: 0.1115\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}